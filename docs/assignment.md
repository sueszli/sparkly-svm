see: https://tuwel.tuwien.ac.at/pluginfile.php/3988544/mod_page/content/1/Exercise%202.html

-   pyspark for text processing
-   use vpn to log into server: https://jupyter01.lbd.hpc.tuwien.ac.at/

part 1:

-   same as the previous assignment but this time with RDDs and transformations
-   output to `output_rdd.txt`

part 2:

-   use sparkml and pipelines to create vector representations of the review texts
-   use built in functions for tokenization, stopword removal, and tf-idf calculation, chi-squared feature selection

part 3:

-   train a SVM as a text classifier on the vector representations to predict the category of the review
