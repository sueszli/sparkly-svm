{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.rdd import RDD\n",
    "\n",
    "import pathlib\n",
    "import json\n",
    "import re\n",
    "base_path = pathlib.Path(\"Exercise_2/sparkly-svm/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings."
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"hdfs:///user/dic24_shared/amazon-reviews/full/reviews_devset.json\"\n",
    "STOPWORD_PATH = base_path.parent/\"data/stopwords.txt\"\n",
    "OUTPUT_PATH = base_path.parent/\"data/output_rdd.txt\"\n",
    "\n",
    "conf = SparkConf().setAppName(\"chi2\").setMaster(\"yarn\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenization, case folding, stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(STOPWORD_PATH, 'r') as file:\n",
    "    stopwords = file.read().splitlines()\n",
    "\n",
    "regex = r'[ \\t\\d()\\[\\]{}.!?,;:+=\\-_\"\\'~#@&*%€$§\\/]+'\n",
    "get_terms = lambda text: [t for t in re.split(regex, text.lower()) if t and t not in stopwords]\n",
    "terms_cat: RDD = sc.textFile(str(DATA_PATH)) \\\n",
    "                .map(json.loads) \\\n",
    "                .map(lambda jsn: (jsn[\"reviewText\"], jsn[\"category\"])) \\\n",
    "                .map(lambda tc: (get_terms(tc[0]), tc[1]))  # type: ignore\n",
    "terms_cat.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chi2 calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(cat, count), ...]\n",
    "cat_count: RDD = terms_cat.map(lambda x: (x[1], 1)).reduceByKey(lambda a, b: a + b)  # type: ignore\n",
    "cat_count_broadcast = sc.broadcast(dict(cat_count.collect()))\n",
    "get_cat_count = lambda cat: cat_count_broadcast.value[cat]\n",
    "\n",
    "# [(term, count), ...]\n",
    "term_count: RDD = terms_cat.flatMap(lambda x: [(t, 1) for t in x[0]]).reduceByKey(lambda a, b: a + b)  # type: ignore\n",
    "term_count_broadcast = sc.broadcast(dict(term_count.collect()))\n",
    "get_term_count = lambda term: term_count_broadcast.value[term]\n",
    "\n",
    "# [((term, cat), count), ...]\n",
    "term_cat_count: RDD = terms_cat.flatMap(lambda x: [((t, x[1]), 1) for t in x[0]]).reduceByKey(lambda a, b: a + b)  # type: ignore\n",
    "term_cat_count_broadcast = sc.broadcast(dict(term_cat_count.collect()))\n",
    "get_term_cat_count = lambda term, cat: term_cat_count_broadcast.value[(term, cat)]\n",
    "\n",
    "# [(cat, [(term, chi2), ...]), ...]\n",
    "N: int = sc.textFile(str(DATA_PATH)).count()\n",
    "get_chi2 = lambda n11, n10, n01, n00: N * (n11 * n00 - n10 * n01) ** 2 / ((n11 + n10) * (n01 + n00) * (n11 + n01) * (n10 + n00))\n",
    "cat_term_chi2s_top75: RDD = term_cat_count \\\n",
    "    .map(lambda tc_c: (\n",
    "        tc_c[0][1], # cat\n",
    "        (\n",
    "            tc_c[0][0], # term\n",
    "            get_chi2(\n",
    "                n11=tc_c[1],\n",
    "                n10=get_term_count(tc_c[0][0]) - tc_c[1],\n",
    "                n01=get_cat_count(tc_c[0][1]) - tc_c[1],\n",
    "                n00=N - tc_c[1] - get_term_count(tc_c[0][0]) - get_cat_count(tc_c[0][1])\n",
    "            )\n",
    "        )\n",
    "    )) \\\n",
    "    .groupByKey() \\\n",
    "    .sortByKey() \\\n",
    "    .mapValues(lambda t_chi2s: sorted(t_chi2s, key=lambda x: x[1], reverse=True)[:75])\n",
    "sorted_top75_terms = cat_term_chi2s_top75.flatMap(lambda x: [t[0] for t in x[1]]).distinct().sortBy(lambda x: x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_PATH, \"w\") as f:\n",
    "    for cat, term_chi2s in cat_term_chi2s_top75.collect():\n",
    "        f.write(f\"{cat} {' '.join([f'{term}:{chi2}' for term, chi2 in term_chi2s])}\\n\")\n",
    "    f.write(\" \".join(sorted_top75_terms.collect()))\n",
    "\n",
    "terms_cat.unpersist()\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (DIC24)",
   "language": "python",
   "name": "python3_dic24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
